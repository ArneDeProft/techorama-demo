{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc9b5f3c-4bfd-4ed5-99df-d2a6678a864e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7040bb30-4473-4c72-8c61-1c44cb58794c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Presidio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "772c3944-7396-4d04-a0bd-ce285e0d280d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPDigestAuth\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f319f67-b953-46a8-91d0-30ccf92a5b06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# configure ADX Access\n",
    "ADXappId = dbutils.secrets.get(scope = \"ADXappIP\", key = \"ADXappIP\") \n",
    "ADXappSecret = dbutils.secrets.get(scope = \"ADXappSecret\", key = \"ADXappSecret\") \n",
    "ADXtenantId = dbutils.secrets.get(scope = \"tenantId\", key = \"tenantId\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "499fe811-054e-481b-ab6b-054678261286",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounting: /mnt/databricks\nMount point /mnt/databricks already exists\nOut[41]: [MountInfo(mountPoint='/databricks-datasets', source='databricks-datasets', encryptionType=''),\n MountInfo(mountPoint='/databricks/mlflow-tracking', source='databricks/mlflow-tracking', encryptionType=''),\n MountInfo(mountPoint='/databricks-results', source='databricks-results', encryptionType=''),\n MountInfo(mountPoint='/databricks/mlflow-registry', source='databricks/mlflow-registry', encryptionType=''),\n MountInfo(mountPoint='/mnt/databricks', source='abfss://databricks@adlstechoramathcosters.dfs.core.windows.net/', encryptionType=''),\n MountInfo(mountPoint='/', source='DatabricksRoot', encryptionType='')]"
     ]
    }
   ],
   "source": [
    "# mount the container\n",
    "mySourceContainerName = \"databricks\"\n",
    "myStorageAccountName = \"adlstechoramathcosters\"\n",
    "\n",
    "mountPointBatch = exec_mount_container( mySourceContainerName, myStorageAccountName )\n",
    "\n",
    "dbutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30c37329-579c-4f7a-bec2-aeef7857b8b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ehsas = dbutils.secrets.get(scope = \"ehsas\", key = \"ehsas\") \n",
    "ehsaskey = dbutils.secrets.get(scope = \"ehsaskey\", key = \"ehsaskey\") \n",
    "\n",
    "connectionString = 'Endpoint=sb://techorama-apim.servicebus.windows.net/;SharedAccessKeyName='+ehsas+';SharedAccessKey='+ehsaskey+';EntityPath=testappeh'\n",
    "consumerGroup = \"databricks\"\n",
    "\n",
    "receiverTimeoutDuration = datetime.time(0,2,0).strftime(\"PT%HH%MM%SS\") #120 seconds\n",
    "\n",
    "ehConf = {}\n",
    "ehConf['eventhubs.connectionString'] = sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(connectionString)\n",
    "ehConf['eventhubs.consumerGroup'] = consumerGroup\n",
    "ehConf['eventhubs.receiverTimeout'] = receiverTimeoutDuration\n",
    "\n",
    "eventSchema = StructType([\n",
    "  StructField(\"timeStamp\", StringType(), True),\n",
    "  StructField(\"name\", StringType(), True),\n",
    "  StructField(\"metric\", LongType(), True),\n",
    "  StructField(\"source\", StringType(), True)]\n",
    ")\n",
    "\n",
    "\n",
    "ehEventsDF = (\n",
    "  spark\n",
    "  .readStream\n",
    "  .format(\"eventhubs\")\n",
    "  .options(**ehConf)\n",
    "  .option(\"startingPosition\", \"fromStartOfStream\")\n",
    "  .load()\n",
    ")\n",
    "\n",
    "# Is this DF actually a streaming DF?\n",
    "ehEventsDF.isStreaming\n",
    "display( ehEventsDF )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "404aa855-efd7-49bd-a537-ce543ec5ca6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "decoded_df = ehEventsDF.withColumn(\"Body\", F.col(\"body\").cast(\"string\")).select(\"Body\")\n",
    "df_events = decoded_df.withColumn(\"EventData\",F.from_json(F.col(\"Body\"), eventSchema)).select(\"EventData.*\")\n",
    "\n",
    "\n",
    "display( df_events )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb012815-4a3e-478f-bfde-28d11f29ab1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write out data to Azure Data Explorer\n",
    "def exec_AllTaxiTripDataProcessing():\n",
    "\n",
    "    kustoOptions = {\"kustoCluster\":\"https://adxtechoramathcosters.westeurope.kusto.windows.net\", \"kustoDatabase\" : \"techorama\", \"kustoTable\" : \"TestTableSpark\", \"kustoAadAppId\":ADXappId ,\"kustoAadAppSecret\":ADXappSecret, \"kustoAadAuthorityID\":ADXtenantId}\n",
    "\n",
    "    spark.conf.set(\"spark.sql.streaming.checkpointLocation\", \"/mnt/databricks/checkpoints/TechoramaTst1KustoEvents\")\n",
    "\n",
    "    df_kusto_events = df_events.withColumn(\"anonymized_name\", anonymize_series(df_events[\"name\"])) \\\n",
    "        .select(\"timeStamp\", \"anonymized_name\", \"metric\", \"source\") \\\n",
    "        .withColumnRenamed(\"anonymized_name\",\"name\")\n",
    "            \n",
    "   \n",
    "   # https://github.com/Azure/azure-kusto-spark/blob/master/docs/KustoSink.md\n",
    "   \n",
    "    kustoQ = (\n",
    "        df_kusto_events.repartition(16).writeStream.format(\n",
    "            \"com.microsoft.kusto.spark.datasink.KustoSinkProvider\"\n",
    "        )\n",
    "        .option(\"kustoCluster\",kustoOptions[\"kustoCluster\"]) \\\n",
    "        .option(\"kustoDatabase\",kustoOptions[\"kustoDatabase\"]) \\\n",
    "        .option(\"kustoTable\", kustoOptions[\"kustoTable\"]) \\\n",
    "        .option(\"kustoAadAppId\",kustoOptions[\"kustoAadAppId\"]) \\\n",
    "        .option(\"kustoAadAppSecret\",kustoOptions[\"kustoAadAppSecret\"]) \\\n",
    "        .option(\"kustoAadAuthorityID\",kustoOptions[\"kustoAadAuthorityID\"]) \\\n",
    "        .outputMode(\"Append\") \\\n",
    "        .option(\"tableCreateOptions\",\"CreateIfNotExist\") \\\n",
    "        .option(\"adjustSchema\", \"GenerateDynamicCsvMapping\") \\\n",
    "        .trigger(processingTime=\"10 seconds\") \\\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    kustoQ.awaitTermination()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d63899e5-2b27-4456-a2f5-4dba47c3045e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "exec_AllTaxiTripDataProcessing()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EventHubToADX",
   "notebookOrigID": 245894922675183,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
