{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82e7940d-d761-4dd3-813c-37a04aa0a24a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n|      name|anonymized_name|\n+----------+---------------+\n|  John Doe|   <ANONYMIZED>|\n|Jane Smith|   <ANONYMIZED>|\n+----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from presidio_analyzer import AnalyzerEngine  \n",
    "from presidio_anonymizer import AnonymizerEngine  \n",
    "from presidio_anonymizer.entities import OperatorConfig  \n",
    "from pyspark.sql import SparkSession  \n",
    "from pyspark.sql.functions import pandas_udf, StringType  \n",
    "import pandas as pd  \n",
    "import spacy  \n",
    "  \n",
    "spacy.load('en_core_web_lg')  \n",
    "  \n",
    "analyzer = AnalyzerEngine()  \n",
    "anonymizer = AnonymizerEngine()  \n",
    "  \n",
    "# broadcast the engines to the cluster nodes  \n",
    "spark = SparkSession.builder.getOrCreate()  \n",
    "sc = spark.sparkContext  \n",
    "broadcasted_analyzer = sc.broadcast(analyzer)  \n",
    "broadcasted_anonymizer = sc.broadcast(anonymizer)  \n",
    "  \n",
    "# define a pandas UDF function and a series function over it.  \n",
    "def anonymize_text(text: str) -> str:  \n",
    "    analyzer = broadcasted_analyzer.value  \n",
    "    anonymizer = broadcasted_anonymizer.value  \n",
    "    analyzer_results = analyzer.analyze(text=text, language=\"en\")  \n",
    "    anonymized_results = anonymizer.anonymize(  \n",
    "        text=text,  \n",
    "        analyzer_results=analyzer_results,  \n",
    "        operators={  \n",
    "            \"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"<ANONYMIZED>\"})  \n",
    "        },  \n",
    "    )  \n",
    "    return anonymized_results.text  \n",
    "  \n",
    "@pandas_udf(StringType())  \n",
    "def anonymize_series(s: pd.Series) -> pd.Series:  \n",
    "    return s.apply(anonymize_text)  \n",
    "  \n",
    "# Example usage with a DataFrame  \n",
    "#data = [(\"John Doe\",), (\"Jane Smith\",)]  \n",
    "#columns = [\"name\"]  \n",
    "#df = spark.createDataFrame(data, columns)  \n",
    "  \n",
    "# Apply the anonymize_series function to the 'name' column  \n",
    "#df = df.withColumn(\"anonymized_name\", anonymize_series(df[\"name\"]))  \n",
    "#df.show()  \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3253860941425496,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Presidio",
   "notebookOrigID": 319067592457656,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
